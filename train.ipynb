{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from torch.distributions import Normal\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
    "import imageio\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from stable_baselines3.dqn.policies import MlpPolicy\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr  2 00:25:49 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.06              Driver Version: 545.23.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1080 Ti     On  | 00000000:01:00.0 Off |                  N/A |\n",
      "|  5%   47C    P8              17W / 250W |      4MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "# clean up memory forcefully\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, observations, actions):\n",
    "        self.observations = torch.tensor(observations, dtype=torch.float32,device=device)\n",
    "        self.actions = torch.tensor(actions, dtype=torch.float32,device=device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.observations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        observation = self.observations[idx]\n",
    "        action = self.actions[idx]\n",
    "        return observation, action\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 4) (1000000,)\n",
      "[-0.03013654  0.21001437 -0.04612853 -0.34675622] 1\n"
     ]
    }
   ],
   "source": [
    "env_id = \"CartPole-v1\"\n",
    "# env = make_vec_env(env_id, n_envs=1)\n",
    "# read /mnt/nfs/work/c98181/RL/dataset/CartPole-v1...npy\n",
    "observations= np.load(\"/mnt/nfs/work/c98181/RL/dataset/CartPole-v1_1M_obs.npy\", allow_pickle=True)\n",
    "actions = np.load(\"/mnt/nfs/work/c98181/RL/dataset/CartPole-v1_1M_actions.npy\", allow_pickle=True)\n",
    "observations=observations.squeeze()\n",
    "actions=actions.squeeze()\n",
    "# observations = observations[:1000]\n",
    "# actions = actions[:1000]\n",
    "print(observations.shape, actions.shape)\n",
    "print(observations[0], actions[0])\n",
    "\n",
    "# print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydataset(Dataset):\n",
    "    def __init__(self, observations, actions):\n",
    "        self.observations = torch.tensor(observations, dtype=torch.float32).to(device)\n",
    "        self.actions = torch.tensor(actions, dtype=torch.float32).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.observations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        observation = self.observations[idx]\n",
    "        action = self.actions[idx]\n",
    "        return observation, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_network = PolicyNetwork(\n",
    "    4, 2).to(device)\n",
    "\n",
    "prev = PolicyNetwork(\n",
    "    4, 2).to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(policy_network.parameters(), lr=(1e-3))\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=1)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 300\n",
    "batch_size = 512\n",
    "\n",
    "dataset = mydataset(observations=observations, actions=actions)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "graph=[]\n",
    "eval_rewards=[]\n",
    "for epoch in range(num_epochs):\n",
    "    policy_network.train()\n",
    "\n",
    "    # Compute the log probabilities of the actions\n",
    "    pbar=tqdm(dataloader,position=0,leave=True)\n",
    "    loss_record=[]\n",
    "    # step=0\n",
    "    for step, (obs_batch,act_batch) in enumerate(pbar):\n",
    "        # obs_batch = torch.tensor(np.array(obs_batch), dtype=torch.float32).to(device)\n",
    "        # act_batch = torch.tensor(np.array(act_batch), dtype=torch.float32).to(device)\n",
    "        if step % 100 == 0:\n",
    "          prev.load_state_dict(policy_network.state_dict())\n",
    "          prev.eval()\n",
    "        # Get the log probabilities of the actions\n",
    "        \n",
    "        softmax = policy_network(obs_batch)\n",
    "        # print(softmax.shape, act_batch.shape)\n",
    "        model_act_sample = Categorical(softmax).sample()\n",
    "        policy_chosen_logps = Categorical(softmax).log_prob(act_batch)\n",
    "        policy_rejected_logps = Categorical(softmax).log_prob(model_act_sample)\n",
    "        with torch.no_grad():\n",
    "            reference_chosen_logps = Categorical(prev(obs_batch)).log_prob(act_batch)\n",
    "            reference_rejected_logps = Categorical(prev(obs_batch)).log_prob(model_act_sample)\n",
    "          \n",
    "\n",
    "        pi_logratios = policy_chosen_logps - policy_rejected_logps\n",
    "        ref_logratios = reference_chosen_logps - reference_rejected_logps\n",
    "\n",
    "        # chosen_KL = (policy_chosen_logps - reference_chosen_logps).mean().clamp(min=0)\n",
    "        # reject_KL = (policy_rejected_logps - reference_rejected_logps).mean().clamp(min=0)\n",
    "\n",
    "        logits = pi_logratios - ref_logratios\n",
    "\n",
    "        chosen_logratios = policy_chosen_logps - reference_chosen_logps\n",
    "        reject_logratios = policy_rejected_logps - reference_rejected_logps\n",
    "\n",
    "        # logits = chosen_logratios - reject_logratios\n",
    "\n",
    "        if epoch <= 10:\n",
    "          loss = - (policy_chosen_logps).mean()\n",
    "        else:\n",
    "          beta = 1\n",
    "          losses = (\n",
    "                  -F.logsigmoid(beta * logits)\n",
    "              )\n",
    "          # loss = losses.mean()\n",
    "        #   losses = torch.cat((1 - F.logsigmoid(beta * (chosen_logratios - reject_KL)), 1 - F.logsigmoid(beta * (chosen_KL - reject_logratios))), 0)\n",
    "          loss = losses.mean()\n",
    "        # Optimize the policy\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_description((f\"Epoch [{epoch+1}/{num_epochs}]\"))\n",
    "        positive_reward = chosen_logratios.detach().mean().item()\n",
    "        negative_reward = reject_logratios.detach().mean().item()\n",
    "        pbar.set_postfix({\"loss\":loss.detach().item(), \"positive_reward\": positive_reward, \"negative_reward\": negative_reward, \"margin\": positive_reward - negative_reward})\n",
    "\n",
    "\n",
    "        #scheduler\n",
    "\n",
    "        loss_record.append(loss.detach().item())\n",
    "    scheduler.step()\n",
    "    graph.append(sum(loss_record)/len(loss_record))\n",
    "\n",
    "    policy_network.eval()  # 切换到评估模式\n",
    "\n",
    "    env = make_vec_env(env_id, n_envs=1)\n",
    "\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward=0\n",
    "    # test the policy and save as gif\n",
    "    frames = []\n",
    "    while not done:\n",
    "        state_tensor = torch.tensor([state], dtype=torch.float32).to(device)\n",
    "        with torch.no_grad():\n",
    "            action = Categorical(policy_network(state_tensor)).sample().cpu().numpy()[0]\n",
    "            \n",
    "        state, reward, done, _ = env.step(action)  # 执行动作\n",
    "        total_reward += reward\n",
    "        frame = env.render(mode=\"rgb_array\")  # 获取当前环境的图像\n",
    "        frames.append(frame)  # 添加到帧列表中\n",
    "\n",
    "    # 保存为GIF\n",
    "    image_path = f\"cartpole_epoch_{epoch+1}.gif\"\n",
    "    imageio.mimsave(\"/mnt/nfs/work/c98181/RL/result/\"+env_id+\"/\"+image_path, frames, duration=0.04)  # duration控制帧切换的速度\n",
    "\n",
    "\n",
    "    env.close()\n",
    "    print(total_reward)\n",
    "    eval_rewards.append(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the loss graph\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(graph)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Epoch\")\n",
    "plt.show()\n",
    "\n",
    "# draw the reward graph\n",
    "plt.plot(eval_rewards)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Reward vs Epoch\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000]: 100%|██████████| 879/879 [00:06<00:00, 128.98it/s, loss=0.177]\n",
      "Epoch [2/1000]: 100%|██████████| 879/879 [00:07<00:00, 123.83it/s, loss=0.154]\n",
      "Epoch [3/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.90it/s, loss=0.166]\n",
      "Epoch [4/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.29it/s, loss=0.135]\n",
      "Epoch [5/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.69it/s, loss=0.131]\n",
      "Epoch [6/1000]: 100%|██████████| 879/879 [00:07<00:00, 123.91it/s, loss=0.131] \n",
      "Epoch [7/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.03it/s, loss=0.148]\n",
      "Epoch [8/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.46it/s, loss=0.128] \n",
      "Epoch [9/1000]: 100%|██████████| 879/879 [00:07<00:00, 123.63it/s, loss=0.134] \n",
      "Epoch [10/1000]: 100%|██████████| 879/879 [00:07<00:00, 123.16it/s, loss=0.138] \n",
      "Epoch [11/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.48it/s, loss=0.113] \n",
      "Epoch [12/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.77it/s, loss=0.123] \n",
      "Epoch [13/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.00it/s, loss=0.143] \n",
      "Epoch [14/1000]: 100%|██████████| 879/879 [00:06<00:00, 125.69it/s, loss=0.125] \n",
      "Epoch [15/1000]: 100%|██████████| 879/879 [00:07<00:00, 124.15it/s, loss=0.124] \n",
      "Epoch [16/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.11it/s, loss=0.113] \n",
      "Epoch [17/1000]: 100%|██████████| 879/879 [00:07<00:00, 124.30it/s, loss=0.101] \n",
      "Epoch [18/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.92it/s, loss=0.117] \n",
      "Epoch [19/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.12it/s, loss=0.118] \n",
      "Epoch [20/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.80it/s, loss=0.117] \n",
      "Epoch [21/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.70it/s, loss=0.115] \n",
      "Epoch [22/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.51it/s, loss=0.1]   \n",
      "Epoch [23/1000]: 100%|██████████| 879/879 [00:07<00:00, 123.63it/s, loss=0.0971]\n",
      "Epoch [24/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.23it/s, loss=0.129] \n",
      "Epoch [25/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.43it/s, loss=0.133] \n",
      "Epoch [26/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.29it/s, loss=0.0992]\n",
      "Epoch [27/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.51it/s, loss=0.131] \n",
      "Epoch [28/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.37it/s, loss=0.13]  \n",
      "Epoch [29/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.80it/s, loss=0.109] \n",
      "Epoch [30/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.46it/s, loss=0.106] \n",
      "Epoch [31/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.23it/s, loss=0.0955]\n",
      "Epoch [32/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.19it/s, loss=0.11]  \n",
      "Epoch [33/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.80it/s, loss=0.123] \n",
      "Epoch [34/1000]: 100%|██████████| 879/879 [00:07<00:00, 123.22it/s, loss=0.095] \n",
      "Epoch [35/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.07it/s, loss=0.0986]\n",
      "Epoch [36/1000]: 100%|██████████| 879/879 [00:07<00:00, 119.12it/s, loss=0.106] \n",
      "Epoch [37/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.68it/s, loss=0.132] \n",
      "Epoch [38/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.57it/s, loss=0.113] \n",
      "Epoch [39/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.47it/s, loss=0.114] \n",
      "Epoch [40/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.84it/s, loss=0.0994]\n",
      "Epoch [41/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.40it/s, loss=0.109] \n",
      "Epoch [42/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.84it/s, loss=0.0917]\n",
      "Epoch [43/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.01it/s, loss=0.117] \n",
      "Epoch [44/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.99it/s, loss=0.0996]\n",
      "Epoch [45/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.59it/s, loss=0.122] \n",
      "Epoch [46/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.37it/s, loss=0.108] \n",
      "Epoch [47/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.04it/s, loss=0.107] \n",
      "Epoch [48/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.31it/s, loss=0.0874]\n",
      "Epoch [49/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.10it/s, loss=0.131] \n",
      "Epoch [50/1000]: 100%|██████████| 879/879 [00:07<00:00, 123.31it/s, loss=0.128] \n",
      "Epoch [51/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.98it/s, loss=0.104] \n",
      "Epoch [52/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.09it/s, loss=0.103] \n",
      "Epoch [53/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.67it/s, loss=0.0957]\n",
      "Epoch [54/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.98it/s, loss=0.113] \n",
      "Epoch [55/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.17it/s, loss=0.129] \n",
      "Epoch [56/1000]: 100%|██████████| 879/879 [00:07<00:00, 123.14it/s, loss=0.0978]\n",
      "Epoch [57/1000]: 100%|██████████| 879/879 [00:07<00:00, 118.79it/s, loss=0.103] \n",
      "Epoch [58/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.23it/s, loss=0.122] \n",
      "Epoch [59/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.83it/s, loss=0.13]  \n",
      "Epoch [60/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.37it/s, loss=0.114] \n",
      "Epoch [61/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.18it/s, loss=0.118] \n",
      "Epoch [62/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.10it/s, loss=0.0956]\n",
      "Epoch [63/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.65it/s, loss=0.105] \n",
      "Epoch [64/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.80it/s, loss=0.11]  \n",
      "Epoch [65/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.98it/s, loss=0.122] \n",
      "Epoch [66/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.69it/s, loss=0.113] \n",
      "Epoch [67/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.45it/s, loss=0.111] \n",
      "Epoch [68/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.20it/s, loss=0.101] \n",
      "Epoch [69/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.41it/s, loss=0.0931]\n",
      "Epoch [70/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.91it/s, loss=0.0989]\n",
      "Epoch [71/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.14it/s, loss=0.107] \n",
      "Epoch [72/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.18it/s, loss=0.104] \n",
      "Epoch [73/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.72it/s, loss=0.118] \n",
      "Epoch [74/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.57it/s, loss=0.125] \n",
      "Epoch [75/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.23it/s, loss=0.0914]\n",
      "Epoch [76/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.46it/s, loss=0.11]  \n",
      "Epoch [77/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.33it/s, loss=0.102] \n",
      "Epoch [78/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.07it/s, loss=0.107] \n",
      "Epoch [79/1000]: 100%|██████████| 879/879 [00:07<00:00, 119.12it/s, loss=0.109] \n",
      "Epoch [80/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.99it/s, loss=0.111] \n",
      "Epoch [81/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.38it/s, loss=0.104] \n",
      "Epoch [82/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.82it/s, loss=0.111] \n",
      "Epoch [83/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.11it/s, loss=0.0964]\n",
      "Epoch [84/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.76it/s, loss=0.118] \n",
      "Epoch [85/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.67it/s, loss=0.122] \n",
      "Epoch [86/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.48it/s, loss=0.11]  \n",
      "Epoch [87/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.12it/s, loss=0.103] \n",
      "Epoch [88/1000]: 100%|██████████| 879/879 [00:07<00:00, 123.06it/s, loss=0.112] \n",
      "Epoch [89/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.03it/s, loss=0.11]  \n",
      "Epoch [90/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.84it/s, loss=0.0957]\n",
      "Epoch [91/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.19it/s, loss=0.118] \n",
      "Epoch [92/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.44it/s, loss=0.109] \n",
      "Epoch [93/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.49it/s, loss=0.0968]\n",
      "Epoch [94/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.23it/s, loss=0.0931]\n",
      "Epoch [95/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.63it/s, loss=0.101] \n",
      "Epoch [96/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.87it/s, loss=0.102] \n",
      "Epoch [97/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.92it/s, loss=0.136] \n",
      "Epoch [98/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.57it/s, loss=0.095] \n",
      "Epoch [99/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.72it/s, loss=0.0908]\n",
      "Epoch [100/1000]: 100%|██████████| 879/879 [00:07<00:00, 119.06it/s, loss=0.0878]\n",
      "Epoch [101/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.50it/s, loss=0.11]  \n",
      "Epoch [102/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.50it/s, loss=0.105] \n",
      "Epoch [103/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.87it/s, loss=0.103] \n",
      "Epoch [104/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.70it/s, loss=0.102] \n",
      "Epoch [105/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.63it/s, loss=0.0819]\n",
      "Epoch [106/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.16it/s, loss=0.0965]\n",
      "Epoch [107/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.39it/s, loss=0.119] \n",
      "Epoch [108/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.62it/s, loss=0.0987]\n",
      "Epoch [109/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.90it/s, loss=0.105] \n",
      "Epoch [110/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.27it/s, loss=0.0919]\n",
      "Epoch [111/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.17it/s, loss=0.097] \n",
      "Epoch [112/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.00it/s, loss=0.117] \n",
      "Epoch [113/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.67it/s, loss=0.0944]\n",
      "Epoch [114/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.33it/s, loss=0.0975]\n",
      "Epoch [115/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.80it/s, loss=0.0975]\n",
      "Epoch [116/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.02it/s, loss=0.0812]\n",
      "Epoch [117/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.47it/s, loss=0.1]   \n",
      "Epoch [118/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.75it/s, loss=0.102] \n",
      "Epoch [119/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.84it/s, loss=0.111] \n",
      "Epoch [120/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.97it/s, loss=0.125] \n",
      "Epoch [121/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.44it/s, loss=0.11]  \n",
      "Epoch [122/1000]: 100%|██████████| 879/879 [00:07<00:00, 118.86it/s, loss=0.122] \n",
      "Epoch [123/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.71it/s, loss=0.113] \n",
      "Epoch [124/1000]: 100%|██████████| 879/879 [00:07<00:00, 123.19it/s, loss=0.107] \n",
      "Epoch [125/1000]: 100%|██████████| 879/879 [00:07<00:00, 119.90it/s, loss=0.128] \n",
      "Epoch [126/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.90it/s, loss=0.11]  \n",
      "Epoch [127/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.68it/s, loss=0.0965]\n",
      "Epoch [128/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.62it/s, loss=0.0979]\n",
      "Epoch [129/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.67it/s, loss=0.0954]\n",
      "Epoch [130/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.02it/s, loss=0.105] \n",
      "Epoch [131/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.57it/s, loss=0.107] \n",
      "Epoch [132/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.80it/s, loss=0.0973]\n",
      "Epoch [133/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.66it/s, loss=0.0977]\n",
      "Epoch [134/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.44it/s, loss=0.111] \n",
      "Epoch [135/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.46it/s, loss=0.112] \n",
      "Epoch [136/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.41it/s, loss=0.115] \n",
      "Epoch [137/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.98it/s, loss=0.118] \n",
      "Epoch [138/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.03it/s, loss=0.0908]\n",
      "Epoch [139/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.45it/s, loss=0.0964]\n",
      "Epoch [140/1000]: 100%|██████████| 879/879 [00:07<00:00, 119.48it/s, loss=0.0955]\n",
      "Epoch [141/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.21it/s, loss=0.101] \n",
      "Epoch [142/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.97it/s, loss=0.116] \n",
      "Epoch [143/1000]: 100%|██████████| 879/879 [00:07<00:00, 119.99it/s, loss=0.101] \n",
      "Epoch [144/1000]: 100%|██████████| 879/879 [00:07<00:00, 119.01it/s, loss=0.088] \n",
      "Epoch [145/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.26it/s, loss=0.11]  \n",
      "Epoch [146/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.17it/s, loss=0.106] \n",
      "Epoch [147/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.17it/s, loss=0.0951]\n",
      "Epoch [148/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.47it/s, loss=0.104] \n",
      "Epoch [149/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.07it/s, loss=0.0923]\n",
      "Epoch [150/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.78it/s, loss=0.101] \n",
      "Epoch [151/1000]: 100%|██████████| 879/879 [00:07<00:00, 119.79it/s, loss=0.118] \n",
      "Epoch [152/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.61it/s, loss=0.0878]\n",
      "Epoch [153/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.06it/s, loss=0.0903]\n",
      "Epoch [154/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.49it/s, loss=0.0953]\n",
      "Epoch [155/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.27it/s, loss=0.103] \n",
      "Epoch [156/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.38it/s, loss=0.107] \n",
      "Epoch [157/1000]: 100%|██████████| 879/879 [00:07<00:00, 119.90it/s, loss=0.104] \n",
      "Epoch [158/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.79it/s, loss=0.0947]\n",
      "Epoch [159/1000]: 100%|██████████| 879/879 [00:07<00:00, 119.87it/s, loss=0.0892]\n",
      "Epoch [160/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.66it/s, loss=0.108] \n",
      "Epoch [161/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.65it/s, loss=0.0896]\n",
      "Epoch [162/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.45it/s, loss=0.128] \n",
      "Epoch [163/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.60it/s, loss=0.0867]\n",
      "Epoch [164/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.53it/s, loss=0.0975]\n",
      "Epoch [165/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.06it/s, loss=0.0975]\n",
      "Epoch [166/1000]: 100%|██████████| 879/879 [00:07<00:00, 119.39it/s, loss=0.105] \n",
      "Epoch [167/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.15it/s, loss=0.109] \n",
      "Epoch [168/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.53it/s, loss=0.104] \n",
      "Epoch [169/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.59it/s, loss=0.113] \n",
      "Epoch [170/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.76it/s, loss=0.0986]\n",
      "Epoch [171/1000]: 100%|██████████| 879/879 [00:07<00:00, 119.67it/s, loss=0.116] \n",
      "Epoch [172/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.38it/s, loss=0.108] \n",
      "Epoch [173/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.65it/s, loss=0.101] \n",
      "Epoch [174/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.11it/s, loss=0.0953]\n",
      "Epoch [175/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.06it/s, loss=0.102] \n",
      "Epoch [176/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.66it/s, loss=0.0984]\n",
      "Epoch [177/1000]: 100%|██████████| 879/879 [00:07<00:00, 119.89it/s, loss=0.0832]\n",
      "Epoch [178/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.78it/s, loss=0.106] \n",
      "Epoch [179/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.62it/s, loss=0.106] \n",
      "Epoch [180/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.89it/s, loss=0.11]  \n",
      "Epoch [181/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.75it/s, loss=0.108] \n",
      "Epoch [182/1000]: 100%|██████████| 879/879 [00:07<00:00, 119.41it/s, loss=0.0987]\n",
      "Epoch [183/1000]: 100%|██████████| 879/879 [00:07<00:00, 118.78it/s, loss=0.0829]\n",
      "Epoch [184/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.01it/s, loss=0.109] \n",
      "Epoch [185/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.27it/s, loss=0.103] \n",
      "Epoch [186/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.15it/s, loss=0.111] \n",
      "Epoch [187/1000]: 100%|██████████| 879/879 [00:07<00:00, 118.38it/s, loss=0.0933]\n",
      "Epoch [188/1000]: 100%|██████████| 879/879 [00:07<00:00, 125.45it/s, loss=0.0838]\n",
      "Epoch [189/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.78it/s, loss=0.107] \n",
      "Epoch [190/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.62it/s, loss=0.104] \n",
      "Epoch [191/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.52it/s, loss=0.119] \n",
      "Epoch [192/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.55it/s, loss=0.1]   \n",
      "Epoch [193/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.34it/s, loss=0.102] \n",
      "Epoch [194/1000]: 100%|██████████| 879/879 [00:07<00:00, 119.77it/s, loss=0.126] \n",
      "Epoch [195/1000]: 100%|██████████| 879/879 [00:07<00:00, 122.56it/s, loss=0.102] \n",
      "Epoch [196/1000]: 100%|██████████| 879/879 [00:07<00:00, 120.82it/s, loss=0.105] \n",
      "Epoch [197/1000]: 100%|██████████| 879/879 [00:07<00:00, 121.16it/s, loss=0.0942]\n",
      "Epoch [198/1000]: 100%|██████████| 879/879 [00:07<00:00, 119.22it/s, loss=0.0873]\n"
     ]
    }
   ],
   "source": [
    "# show line number below\n",
    "\n",
    "\n",
    "policy_network = PolicyNetwork(\n",
    "    4, 2).to(device)\n",
    "# nn init kaiming\n",
    "torch.nn.init.kaiming_normal_(policy_network.fc1.weight)\n",
    "torch.nn.init.kaiming_normal_(policy_network.fc2.weight)\n",
    "torch.nn.init.kaiming_normal_(policy_network.fc3.weight)\n",
    "\n",
    "# build training set and validation set\n",
    "train_size = int(0.9 * len(observations))\n",
    "train_observations = observations[:train_size]\n",
    "train_actions = actions[:train_size]\n",
    "val_observations = observations[train_size:]\n",
    "val_actions = actions[train_size:]\n",
    "\n",
    "# build dataset\n",
    "train_dataset = CustomDataset(train_observations, train_actions)\n",
    "val_dataset = CustomDataset(val_observations, val_actions)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(policy_network.parameters(), lr=(5e-4),weight_decay=1e-4,eps=1e-8)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=1)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "batch_size = 1024\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset , batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset , batch_size=batch_size, shuffle=True)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "graph=[]\n",
    "val_losses=[]\n",
    "eval_rewards=[]\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch+1 % 50 == 0:\n",
    "        torch.save(policy_network.state_dict(), f\"/mnt/nfs/work/c98181/RL/result/{env_id}/model/policy_network_epoch_{epoch+1}.pth\")\n",
    "        # plot the loss graph\n",
    "        plt.plot(graph)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Loss vs Epoch\")\n",
    "        plt.savefig(f\"/mnt/nfs/work/c98181/RL/result/{env_id}/graph/loss_epoch_{epoch+1}.png\")\n",
    "        plt.close()\n",
    "        # plot the reward graph\n",
    "        plt.plot(eval_rewards)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Reward\")\n",
    "        plt.title(\"Reward vs Epoch\")\n",
    "        plt.savefig(f\"/mnt/nfs/work/c98181/RL/result/{env_id}/graph/reward_epoch_{epoch+1}.png\")\n",
    "        plt.close()\n",
    "        # plot the val loss graph\n",
    "        plt.plot(val_losses)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Val Loss\")\n",
    "        plt.title(\"Val Loss vs Epoch\")\n",
    "        plt.savefig(f\"/mnt/nfs/work/c98181/RL/result/{env_id}/graph/val_loss_epoch_{epoch+1}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    policy_network.train()\n",
    "\n",
    "    # Compute the log probabilities of the actions\n",
    "    pbar=tqdm(train_dataloader,position=0,leave=True)\n",
    "    loss_record=[]\n",
    "\n",
    "    for step, (obs_batch,act_batch) in enumerate(pbar):\n",
    "\n",
    "        \n",
    "        logits = policy_network(obs_batch)\n",
    "        # cross entropy\n",
    "        loss=loss_func(logits, act_batch.long())\n",
    "        \n",
    "        # Optimize the policy\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pbar.set_description((f\"Epoch [{epoch+1}/{num_epochs}]\"))\n",
    "        pbar.set_postfix({\"loss\":loss.detach().item()})\n",
    "\n",
    "\n",
    "        #scheduler\n",
    "\n",
    "        loss_record.append(loss.detach().item())\n",
    "    scheduler.step()\n",
    "    graph.append(sum(loss_record)/len(loss_record))\n",
    "    with torch.no_grad():\n",
    "        # validation_loss\n",
    "        val_loss_record=[]\n",
    "        for step, (obs_batch,act_batch) in enumerate(val_dataloader):\n",
    "            logits = policy_network(obs_batch)\n",
    "            loss = loss_func(logits, act_batch.long())\n",
    "            val_loss_record.append(loss.detach().item())\n",
    "        val_loss = sum(val_loss_record)/len(val_loss_record)\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    policy_network.eval()  # 切换到评估模式\n",
    "\n",
    "    env = make_vec_env(env_id, n_envs=1)\n",
    "    # test ten times\n",
    "    total_reward=0\n",
    "    for _ in range(10):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        # test the policy and save as gif\n",
    "        frames = []\n",
    "        while not done:\n",
    "            state_tensor = torch.tensor([state], dtype=torch.float32).to(device)\n",
    "            with torch.no_grad():\n",
    "                pred= policy_network(state_tensor)\n",
    "                action = torch.argmax(pred).cpu().numpy()\n",
    "                # print(action)\n",
    "                \n",
    "            state, reward, done, _ = env.step([action])  # 执行动作\n",
    "            total_reward += reward\n",
    "            frame = env.render(mode=\"rgb_array\")  # 获取当前环境的图像\n",
    "            frames.append(frame)  # 添加到帧列表中\n",
    "\n",
    "    # 保存为GIF\n",
    "    image_path = f\"cartpole_epoch_{epoch+1}.gif\"\n",
    "    imageio.mimsave(\"/mnt/nfs/work/c98181/RL/result/\"+env_id+\"/gif/\"+image_path, frames, duration=0.04)  # duration控制帧切换的速度\n",
    "\n",
    "\n",
    "    env.close()\n",
    "    # print(total_reward/10, val_loss)\n",
    "    \n",
    "    eval_rewards.append(total_reward/10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the loss graph\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(graph)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Epoch\")\n",
    "plt.show()\n",
    "\n",
    "# draw the reward graph\n",
    "plt.plot(eval_rewards)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Reward vs Epoch\")\n",
    "plt.show()\n",
    "# draw the validation loss graph\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.title(\"Validation Loss vs Epoch\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pretrain(self, dataset, n_epochs=10, learning_rate=1e-4,\n",
    "#                  adam_epsilon=1e-8, val_interval=None):\n",
    "#         \"\"\"\n",
    "#         Pretrain a model using behavior cloning:\n",
    "#         supervised learning given an expert dataset.\n",
    "\n",
    "#         NOTE: only Box and Discrete spaces are supported for now.\n",
    "\n",
    "#         :param dataset: (ExpertDataset) Dataset manager\n",
    "#         :param n_epochs: (int) Number of iterations on the training set\n",
    "#         :param learning_rate: (float) Learning rate\n",
    "#         :param adam_epsilon: (float) the epsilon value for the adam optimizer\n",
    "#         :param val_interval: (int) Report training and validation losses every n epochs.\n",
    "#             By default, every 10th of the maximum number of epochs.\n",
    "#         :return: (BaseRLModel) the pretrained model\n",
    "#         \"\"\"\n",
    "#         continuous_actions = isinstance(self.action_space, gym.spaces.Box)\n",
    "#         discrete_actions = isinstance(self.action_space, gym.spaces.Discrete)\n",
    "\n",
    "#         assert discrete_actions or continuous_actions, 'Only Discrete and Box action spaces are supported'\n",
    "\n",
    "#         # Validate the model every 10% of the total number of iteration\n",
    "#         if val_interval is None:\n",
    "#             # Prevent modulo by zero\n",
    "#             if n_epochs < 10:\n",
    "#                 val_interval = 1\n",
    "#             else:\n",
    "#                 val_interval = int(n_epochs / 10)\n",
    "\n",
    "#         with self.graph.as_default():\n",
    "#             with tf.variable_scope('pretrain', reuse=tf.AUTO_REUSE):\n",
    "#                 if continuous_actions:\n",
    "#                     obs_ph, actions_ph, deterministic_actions_ph = self._get_pretrain_placeholders()\n",
    "#                     loss = tf.reduce_mean(tf.square(actions_ph - deterministic_actions_ph))\n",
    "#                 else:\n",
    "#                     obs_ph, actions_ph, actions_logits_ph = self._get_pretrain_placeholders()\n",
    "#                     # actions_ph has a shape if (n_batch,), we reshape it to (n_batch, 1)\n",
    "#                     # so no additional changes is needed in the dataloader\n",
    "#                     actions_ph = tf.expand_dims(actions_ph, axis=1)\n",
    "#                     one_hot_actions = tf.one_hot(actions_ph, self.action_space.n)\n",
    "#                     loss = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "#                         logits=actions_logits_ph,\n",
    "#                         labels=tf.stop_gradient(one_hot_actions)\n",
    "#                     )\n",
    "#                     loss = tf.reduce_mean(loss)\n",
    "#                 optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, epsilon=adam_epsilon)\n",
    "#                 optim_op = optimizer.minimize(loss, var_list=self.params)\n",
    "\n",
    "#             self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#         if self.verbose > 0:\n",
    "#             print(\"Pretraining with Behavior Cloning...\")\n",
    "\n",
    "#         for epoch_idx in range(int(n_epochs)):\n",
    "#             train_loss = 0.0\n",
    "#             # Full pass on the training set\n",
    "#             for _ in range(len(dataset.train_loader)):\n",
    "#                 expert_obs, expert_actions = dataset.get_next_batch('train')\n",
    "#                 feed_dict = {\n",
    "#                     obs_ph: expert_obs,\n",
    "#                     actions_ph: expert_actions,\n",
    "#                 }\n",
    "#                 train_loss_, _ = self.sess.run([loss, optim_op], feed_dict)\n",
    "#                 train_loss += train_loss_\n",
    "\n",
    "#             train_loss /= len(dataset.train_loader)\n",
    "\n",
    "#             if self.verbose > 0 and (epoch_idx + 1) % val_interval == 0:\n",
    "#                 val_loss = 0.0\n",
    "#                 # Full pass on the validation set\n",
    "#                 for _ in range(len(dataset.val_loader)):\n",
    "#                     expert_obs, expert_actions = dataset.get_next_batch('val')\n",
    "#                     val_loss_, = self.sess.run([loss], {obs_ph: expert_obs,\n",
    "#                                                         actions_ph: expert_actions})\n",
    "#                     val_loss += val_loss_\n",
    "\n",
    "#                 val_loss /= len(dataset.val_loader)\n",
    "#                 if self.verbose > 0:\n",
    "#                     print(\"==== Training progress {:.2f}% ====\".format(100 * (epoch_idx + 1) / n_epochs))\n",
    "#                     print('Epoch {}'.format(epoch_idx + 1))\n",
    "#                     print(\"Training loss: {:.6f}, Validation loss: {:.6f}\".format(train_loss, val_loss))\n",
    "#                     print()\n",
    "#             # Free memory\n",
    "#             del expert_obs, expert_actions\n",
    "#         if self.verbose > 0:\n",
    "#             print(\"Pretraining done.\")\n",
    "#         return self\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atari",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
