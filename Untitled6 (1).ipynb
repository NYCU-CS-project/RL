{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# installations primiarly needed for Mujoco\n",
        "!apt-get install -y \\\n",
        "    libgl1-mesa-dev \\\n",
        "    libgl1-mesa-glx \\\n",
        "    libglew-dev \\\n",
        "    libosmesa6-dev \\\n",
        "    software-properties-common\n",
        "\n",
        "!apt-get install -y patchelf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvIa3hWhAZjq",
        "outputId": "f2b4b5ce-8ea6-4b72-ccd5-28956bc66e9d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libglew-dev is already the newest version (2.2.0-4).\n",
            "libgl1-mesa-dev is already the newest version (23.2.1-1ubuntu3.1~22.04.2).\n",
            "libosmesa6-dev is already the newest version (23.2.1-1ubuntu3.1~22.04.2).\n",
            "software-properties-common is already the newest version (0.99.22.9).\n",
            "libgl1-mesa-glx is already the newest version (23.0.4-0ubuntu1~22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "patchelf is already the newest version (0.14.3-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# primarily RL-sepcific requirements\n",
        "%pip install -f https://download.pytorch.org/whl/torch_stable.html \\\n",
        "                free-mujoco-py \\\n",
        "                einops \\\n",
        "                gym==0.23.1 \\\n",
        "                protobuf==3.20.1 \\\n",
        "                git+https://github.com/rail-berkeley/d4rl.git \\\n",
        "                mediapy \\\n",
        "                Pillow==9.0.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGFn75PpASce",
        "outputId": "5d763a0f-0003-4b25-a75d-ba048c9484b2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting git+https://github.com/rail-berkeley/d4rl.git\n",
            "  Cloning https://github.com/rail-berkeley/d4rl.git to /tmp/pip-req-build-xbb5kcnr\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/rail-berkeley/d4rl.git /tmp/pip-req-build-xbb5kcnr\n",
            "  Resolved https://github.com/rail-berkeley/d4rl.git to commit 71a9549f2091accff93eeff68f1f3ab2c0e0a288\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: free-mujoco-py in /usr/local/lib/python3.10/dist-packages (2.1.6)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: gym==0.23.1 in /usr/local/lib/python3.10/dist-packages (0.23.1)\n",
            "Requirement already satisfied: protobuf==3.20.1 in /usr/local/lib/python3.10/dist-packages (3.20.1)\n",
            "Requirement already satisfied: mediapy in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: Pillow==9.0.0 in /usr/local/lib/python3.10/dist-packages (9.0.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.23.1) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.23.1) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.23.1) (0.0.8)\n",
            "Requirement already satisfied: Cython<0.30.0,>=0.29.24 in /usr/local/lib/python3.10/dist-packages (from free-mujoco-py) (0.29.37)\n",
            "Requirement already satisfied: cffi<2.0.0,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from free-mujoco-py) (1.16.0)\n",
            "Requirement already satisfied: fasteners==0.15 in /usr/local/lib/python3.10/dist-packages (from free-mujoco-py) (0.15)\n",
            "Requirement already satisfied: glfw<2.0.0,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from free-mujoco-py) (1.12.0)\n",
            "Requirement already satisfied: imageio<3.0.0,>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from free-mujoco-py) (2.31.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fasteners==0.15->free-mujoco-py) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=0.1 in /usr/local/lib/python3.10/dist-packages (from fasteners==0.15->free-mujoco-py) (1.6)\n",
            "Collecting mjrl@ git+https://github.com/aravindr93/mjrl@master#egg=mjrl (from D4RL==1.1)\n",
            "  Cloning https://github.com/aravindr93/mjrl (to revision master) to /tmp/pip-install-246_5q09/mjrl_48c2e63641f14133b795e0101a5d31f8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/aravindr93/mjrl /tmp/pip-install-246_5q09/mjrl_48c2e63641f14133b795e0101a5d31f8\n",
            "  Resolved https://github.com/aravindr93/mjrl to commit 3871d93763d3b49c4741e6daeaebbc605fe140dc\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: mujoco_py in /usr/local/lib/python3.10/dist-packages (from D4RL==1.1) (2.1.2.14)\n",
            "Requirement already satisfied: pybullet in /usr/local/lib/python3.10/dist-packages (from D4RL==1.1) (3.2.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from D4RL==1.1) (3.9.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from D4RL==1.1) (2.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from D4RL==1.1) (8.1.7)\n",
            "Requirement already satisfied: dm_control>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from D4RL==1.1) (1.0.16)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from mediapy) (7.34.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapy) (3.7.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi<2.0.0,>=1.15.0->free-mujoco-py) (2.21)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (1.4.0)\n",
            "Requirement already satisfied: dm-env in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (1.6)\n",
            "Requirement already satisfied: dm-tree!=0.1.2 in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (0.1.8)\n",
            "Requirement already satisfied: labmaze in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (1.0.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (4.9.4)\n",
            "Requirement already satisfied: mujoco>=3.1.1 in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (3.1.3)\n",
            "Requirement already satisfied: pyopengl>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (3.1.7)\n",
            "Requirement already satisfied: pyparsing>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (2.31.0)\n",
            "Requirement already satisfied: setuptools!=50.0.0 in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (67.7.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dm_control>=1.0.3->D4RL==1.1) (4.66.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->mediapy) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->mediapy) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->mediapy) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->mediapy) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->mediapy) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->mediapy) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->mediapy) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->mediapy) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->mediapy) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapy) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapy) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapy) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapy) (24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapy) (2.8.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->mediapy) (0.8.3)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.10/dist-packages (from mujoco>=3.1.1->dm_control>=1.0.3->D4RL==1.1) (1.7.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->mediapy) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->mediapy) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dm_control>=1.0.3->D4RL==1.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dm_control>=1.0.3->D4RL==1.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dm_control>=1.0.3->D4RL==1.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dm_control>=1.0.3->D4RL==1.1) (2024.2.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=3.1.1->dm_control>=1.0.3->D4RL==1.1) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=3.1.1->dm_control>=1.0.3->D4RL==1.1) (6.3.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=3.1.1->dm_control>=1.0.3->D4RL==1.1) (4.10.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=3.1.1->dm_control>=1.0.3->D4RL==1.1) (3.18.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import d4rl"
      ],
      "metadata": {
        "id": "DIhtH5SRBBtS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set mujoco env path if not already set\n",
        "# %env LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mujoco200/bin\n",
        "\n",
        "import gym\n",
        "import d4rl # Import required to register environments\n",
        "\n",
        "\n",
        "env = gym.make('Walker2d-v3')\n",
        "env.reset()\n",
        "env.step(env.action_space.sample())\n",
        "env.close()\n",
        "print(\"mujoco-py check passed\")\n",
        "\n",
        "env = gym.make('walker2d-medium-v2')\n",
        "env.reset()\n",
        "env.step(env.action_space.sample())\n",
        "env.close()\n",
        "print(\"d4rl check passed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeRmR0cmyDrW",
        "outputId": "9857a8f2-a1e3-4e76-e724-e566ae5be704"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mujoco-py check passed\n",
            "d4rl check passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import d4rl  # Import D4RL datasets\n",
        "\n",
        "# Load the gym environment\n",
        "env = gym.make('maze2d-umaze-v1')  # Use an environment name from the D4RL dataset\n",
        "env.reset()\n",
        "dataset = env.get_dataset()  # Get the dataset for the environment\n",
        "\n",
        "# Take a single step in the environment\n",
        "obs, reward, done, info = env.step(env.action_space.sample())\n",
        "\n",
        "print(f\"Observation: {obs}\")\n",
        "print(f\"Reward: {reward}\")\n",
        "print(f\"Done: {done}\")\n",
        "print(f\"Info: {info}\")\n",
        "\n",
        "# Make sure to check the dataset structure\n",
        "print(f\"Keys in dataset: {dataset.keys()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czmISmEOBuql",
        "outputId": "0f0c02c5-3efc-492b-d677-2659961c314f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "load datafile: 100%|██████████| 8/8 [00:00<00:00, 19.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation: [ 2.96235634  2.90449218  0.18383036 -0.06991828]\n",
            "Reward: 0.0\n",
            "Done: False\n",
            "Info: {}\n",
            "Keys in dataset: dict_keys(['actions', 'infos/goal', 'infos/qpos', 'infos/qvel', 'observations', 'rewards', 'terminals', 'timeouts'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set mujoco env path if not already set\n",
        "# %env LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mujoco200/bin\n",
        "\n",
        "from copy import deepcopy\n",
        "import gym\n",
        "import d4rl  # Import required to register environments\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "\n",
        "# Define the policy network\n",
        "\n",
        "\n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, output_dim*2)\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.prev = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        mu = x[:, :self.output_dim]\n",
        "        log_std = x[:, self.output_dim:]\n",
        "        std = F.softplus(log_std)\n",
        "        return mu, std\n",
        "\n",
        "\n",
        "# Define direct preference optimization loss\n",
        "# Loss=-log(sigmoid(policy-ref)=(p_w-p_l)-(ref_w-ref_l)=(p_w - ref_w) - (p_l - ref_l))\n",
        "# ref=model_(t-1) and policy=model_t\n",
        "def dpo_loss(policy_chosen_logps, policy_rejected_logps, reference_chosen_logps, reference_rejected_logps, beta=1.0):\n",
        "    pi_logratios = policy_chosen_logps - policy_rejected_logps\n",
        "    ref_logratios = reference_chosen_logps - reference_rejected_logps\n",
        "\n",
        "    logits = pi_logratios - ref_logratios\n",
        "\n",
        "    loss = -F.logsigmoid(beta * logits).mean()\n",
        "    return loss\n",
        "\n",
        "\n",
        "env = gym.make('walker2d-medium-v2')\n",
        "dataset = env.get_dataset()\n",
        "obs = dataset['observations']\n",
        "acts = dataset['actions']\n",
        "print(obs.shape, acts.shape)\n",
        "# Define the training loop\n",
        "# Define the policy network\n",
        "policy_network = PolicyNetwork(\n",
        "    env.observation_space.shape[0], env.action_space.shape[0])\n",
        "optimizer = torch.optim.Adam(policy_network.parameters(), lr=1e-3)\n",
        "pre = deepcopy(policy_network)\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 64\n",
        "normal_dist = torch.distributions.Normal(0, 1)\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Sample a batch of observations\n",
        "    indices = np.random.choice(len(obs), batch_size)\n",
        "    obs_batch = torch.tensor(obs[indices], dtype=torch.float32)\n",
        "    act_batch = torch.tensor(acts[indices], dtype=torch.float32)\n",
        "\n",
        "    # Compute the log probabilities of the actions\n",
        "    mu, std = policy_network(obs_batch)\n",
        "    epsilon = normal_dist.sample(mu.shape)\n",
        "    model_act_sample = mu + std * epsilon\n",
        "    model_act_logp = normal_dist.log_prob(epsilon)\n",
        "    expert_act_logp = normal_dist.log_prob((act_batch - mu) / std)\n",
        "\n",
        "    # Compute the log probabilities of the actions under the previous policy\n",
        "    with torch.no_grad():\n",
        "        if policy_network.prev == None:\n",
        "            policy_network.prev = deepcopy(policy_network)\n",
        "\n",
        "        prev_mu, prev_std = policy_network.prev(obs_batch)\n",
        "        prev_model_act_logp = normal_dist.log_prob(\n",
        "            (model_act_sample-prev_mu)/prev_std)\n",
        "        prev_expert_act_logp = normal_dist.log_prob(\n",
        "            (act_batch - prev_mu) / prev_std)\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = -dpo_loss(expert_act_logp, model_act_logp,\n",
        "                     prev_expert_act_logp, prev_model_act_logp, beta=1.0)\n",
        "    # Optimize the policy\n",
        "    if num_epochs % 10 == 1:\n",
        "        policy_network.prev = deepcopy(policy_network)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print the loss\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch +\n",
        "          1, num_epochs, loss.item()))\n"
      ],
      "metadata": {
        "id": "pPIsgcdzDsuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a2a4cef-ac04-4829-91bb-58f6bd7adbd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "load datafile: 100%|██████████| 21/21 [00:05<00:00,  4.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000000, 17) (1000000, 6)\n",
            "Epoch [1/100], Loss: -0.6931\n",
            "Epoch [2/100], Loss: -0.7222\n",
            "Epoch [3/100], Loss: -0.7676\n",
            "Epoch [4/100], Loss: -0.8205\n",
            "Epoch [5/100], Loss: -0.9543\n",
            "Epoch [6/100], Loss: -0.9667\n",
            "Epoch [7/100], Loss: -1.0946\n",
            "Epoch [8/100], Loss: -1.5102\n",
            "Epoch [9/100], Loss: -1.6360\n",
            "Epoch [10/100], Loss: -2.2516\n",
            "Epoch [11/100], Loss: -2.6703\n",
            "Epoch [12/100], Loss: -2.7854\n",
            "Epoch [13/100], Loss: -4.3016\n",
            "Epoch [14/100], Loss: -4.4027\n",
            "Epoch [15/100], Loss: -6.3448\n",
            "Epoch [16/100], Loss: -10.4199\n",
            "Epoch [17/100], Loss: -24.2058\n",
            "Epoch [18/100], Loss: -18.5903\n",
            "Epoch [19/100], Loss: -31.6253\n",
            "Epoch [20/100], Loss: -28.8660\n",
            "Epoch [21/100], Loss: -112.2733\n",
            "Epoch [22/100], Loss: -61.8056\n",
            "Epoch [23/100], Loss: -836.3360\n",
            "Epoch [24/100], Loss: -174.8199\n",
            "Epoch [25/100], Loss: -129.5840\n",
            "Epoch [26/100], Loss: -320.6694\n",
            "Epoch [27/100], Loss: -249.6041\n",
            "Epoch [28/100], Loss: -1080.1365\n",
            "Epoch [29/100], Loss: -3662.7598\n",
            "Epoch [30/100], Loss: -2764.7744\n",
            "Epoch [31/100], Loss: -18833.7266\n",
            "Epoch [32/100], Loss: -279163.6562\n",
            "Epoch [33/100], Loss: -2149044.5000\n",
            "Epoch [34/100], Loss: -27062.9688\n",
            "Epoch [35/100], Loss: -209989.9531\n",
            "Epoch [36/100], Loss: -5882746.0000\n",
            "Epoch [37/100], Loss: -37088.6562"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set mujoco env path if not already set\n",
        "# %env LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mujoco200/bin\n",
        "\n",
        "from copy import deepcopy\n",
        "import gym\n",
        "import d4rl  # Import required to register environments\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "\n",
        "# Define the policy network\n",
        "\n",
        "\n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Define direct preference optimization loss\n",
        "# Loss=-log(sigmoid(policy-ref)=(p_w-p_l)-(ref_w-ref_l)=(p_w - ref_w) - (p_l - ref_l))\n",
        "# ref=model_(t-1) and policy=model_t\n",
        "def dpo_loss(policy_chosen_logps, policy_rejected_logps, reference_chosen_logps, reference_rejected_logps, beta=1.0):\n",
        "    pi_logratios = policy_chosen_logps - policy_rejected_logps\n",
        "    ref_logratios = reference_chosen_logps - reference_rejected_logps\n",
        "\n",
        "    logits = pi_logratios - ref_logratios\n",
        "\n",
        "    loss = -F.logsigmoid(beta * logits).mean()\n",
        "    return loss\n",
        "\n",
        "\n",
        "env = gym.make('minigrid-fourrooms-random-v0')\n",
        "dataset = env.get_dataset()\n",
        "obs = dataset['observations']\n",
        "acts = dataset['actions']\n",
        "print(obs.shape, acts.shape)\n",
        "print(acts[0])\n",
        "# Define the training loop\n",
        "# Define the policy network\n",
        "policy_network = PolicyNetwork(\n",
        "    env.observation_space.shape[0], env.action_space.shape[0])\n",
        "optimizer = torch.optim.Adam(policy_network.parameters(), lr=1e-3)\n",
        "pre = deepcopy(policy_network)\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 64\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Sample a batch of observations\n",
        "    indices = np.random.choice(len(obs), batch_size)\n",
        "    obs_batch = torch.tensor(obs[indices], dtype=torch.float32)\n",
        "    act_batch = torch.tensor(acts[indices], dtype=torch.float32)\n",
        "\n",
        "    # Compute the log probabilities of the actions\n",
        "    p = policy_network(obs_batch)\n",
        "    model_probability_distribution = Categorical(p)\n",
        "    model_act = model_probability_distribution.sample()\n",
        "    act_logp = model_probability_distribution.log_prob(model_act).sum(dim=-1)\n",
        "\n",
        "    # Compute the log probabilities of the actions under the previous policy\n",
        "    with torch.no_grad():\n",
        "        act_prob_old = pre(obs_batch)\n",
        "        act_dist_old = Categorical(act_prob_old)\n",
        "        act_sample_old = act_dist_old.sample()\n",
        "        act_logp_old = act_dist_old.log_prob(act_sample_old).sum(dim=-1)\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = -dpo_loss(act_logp, act_logp_old, act_logp, act_logp_old)\n",
        "    pre = deepcopy(policy_network)\n",
        "    # Optimize the policy\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print the loss\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch +\n",
        "          1, num_epochs, loss.item()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "IXvteo4i5aF0",
        "outputId": "d909d794-e4ea-4aa5-993b-638962d72416"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-726271386485>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'minigrid-fourrooms-random-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'observations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, **kwargs)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;31m# fmt: on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Env\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# Construct the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# Make the environment aware of which spec it came from.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/d4rl/gym_minigrid/envs/fourrooms.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, agent_pos, goal_pos, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mgoal_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_goal_default_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoal_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/d4rl/gym_minigrid/minigrid.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, grid_size, width, height, max_steps, see_through_walls, seed, agent_view_size, **kwargs)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;31m# Initialize the state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/d4rl/gym_minigrid/minigrid.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;31m# Return first observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/d4rl/gym_minigrid/minigrid.py\u001b[0m in \u001b[0;36mgen_obs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \"\"\"\n\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m         \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvis_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_obs_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;31m# Encode the partially observable view into a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/d4rl/gym_minigrid/minigrid.py\u001b[0m in \u001b[0;36mgen_obs_grid\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;31m# Note that this incurs some performance cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msee_through_walls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mvis_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_vis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_view_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_view_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0mvis_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/d4rl/gym_minigrid/minigrid.py\u001b[0m in \u001b[0;36mprocess_vis\u001b[0;34m(grid, agent_pos)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_vis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__former_attrs__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__former_attrs__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'testing'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
          ]
        }
      ]
    }
  ]
}